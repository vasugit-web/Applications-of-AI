{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Classification and Text Extraction\n",
    "\n",
    "### Image Classification:\n",
    "For the image classification we have used CNN to classify the images in three samples, these samples are depending upon how the image looks. The first sample conatins the column based images, the second sample contains only the row bsed samples and the third sample contains blank background samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Siddhant\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Initialising the CNN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Step 1 - Convolution\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "\n",
    "# Step 2 - Pooling\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Adding a second convolutional layer\n",
    "classifier.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Step 3 - Flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Step 4 - Full connection\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "classifier.add(Dense(units = 3, activation = 'softmax'))\n",
    "\n",
    "# Compiling the CNN\n",
    "classifier.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 88 images belonging to 3 classes.\n",
      "Found 32 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('images/train/',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('images/test/',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8000/8000 [==============================] - 2439s 305ms/step - loss: 0.0078 - accuracy: 0.9982 - val_loss: 2.9132e-04 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "8000/8000 [==============================] - 4105s 513ms/step - loss: 1.3783e-05 - accuracy: 1.0000 - val_loss: 1.7527e-05 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "8000/8000 [==============================] - 2764s 345ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 2.3133e-06 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "8000/8000 [==============================] - 2430s 304ms/step - loss: 3.5148e-07 - accuracy: 1.0000 - val_loss: 2.7940e-07 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "8000/8000 [==============================] - 2433s 304ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 2.3842e-07 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "8000/8000 [==============================] - 2420s 302ms/step - loss: 3.1477e-07 - accuracy: 1.0000 - val_loss: 2.3842e-07 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "8000/8000 [==============================] - 2426s 303ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 2.9057e-07 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "8000/8000 [==============================] - 2418s 302ms/step - loss: 3.0688e-07 - accuracy: 1.0000 - val_loss: 2.3842e-07 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "8000/8000 [==============================] - 2422s 303ms/step - loss: 8.3633e-04 - accuracy: 0.9999 - val_loss: 5.7369e-07 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 2428s 304ms/step - loss: 4.4861e-07 - accuracy: 1.0000 - val_loss: 2.3842e-07 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1590a99c0b8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit_generator(training_set,\n",
    "                         steps_per_epoch = 8000,\n",
    "                         epochs = 10,\n",
    "                         validation_data = test_set,\n",
    "                         validation_steps = 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test set:  1.0\n"
     ]
    }
   ],
   "source": [
    "#accuracy\n",
    "accuracy=classifier.evaluate_generator(test_set)\n",
    "print('Accuracy of the model on the test set: ',accuracy[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Sample 1': 0, 'Sample 2': 1, 'Sample 3': 2}"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#imports for testing\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "training_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testing from validation set\n",
    "test_image = image.load_img('images/validation/iCard_021979_1_Daker_Sarah.jpg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = classifier.predict(test_image)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting text from Images\n",
    "\n",
    "Here we will use normalise the image, to improves its accuracy and then use AWS textract to extract the data from the images and then save the output of it in form of CSV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from PIL import Image\n",
    "import boto3\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing functions from function.ipynb in this notebook. By using this approach we can add as many new functions we want or change the functions depending upon the new samples. We just need to import the notebook and the functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import functions\n",
    "from functions import image_norm_sample_one,image_norm_sample_two,image_norm_sample_three,ocr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classification_move() functions classifies the images, normalise it and then extracts the information from the image in one single function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_move(imgpath):\n",
    "    test_image = image.load_img(imgpath, target_size = (64, 64))\n",
    "    test_image = image.img_to_array(test_image)\n",
    "    test_image = np.expand_dims(test_image, axis = 0)\n",
    "    result = classifier.predict(test_image)\n",
    "\n",
    "    if result[0][0] == 1:\n",
    "        print('Normalising the image...')\n",
    "        path = image_norm_sample_one(imgpath)\n",
    "        print('OCR in progress...')\n",
    "        d = ocr(path)\n",
    "    elif result[0][1] == 1:\n",
    "        print('Normalising the image...')\n",
    "        path = image_norm_sample_two(imgpath)\n",
    "        print('OCR in progress...')\n",
    "        d = ocr(path)\n",
    "    else:\n",
    "        print('Normalising the image...')\n",
    "        path = image_norm_sample_three(imgpath)\n",
    "        print('OCR in progress...')\n",
    "        d = ocr(path)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the main function that needs to be called. This function does all the required steps and gives the output in the form of a CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paths\n",
    "currentpath = os.getcwd()\n",
    "basepath = os.path.join(currentpath, 'ocr_test')\n",
    "csvpath = os.path.join(currentpath, 'csv')\n",
    "normalisedpath = os.path.join(currentpath, 'normalised')\n",
    "backupnorm = os.path.join(currentpath, 'backup_normalised')\n",
    "filename = 'file1'\n",
    "savepath = os.path.join(csvpath,filename + \".csv\")\n",
    "\n",
    "def ocr_process(basepath):\n",
    "    df = pd.DataFrame()\n",
    "    for entry in os.listdir(basepath):\n",
    "        imgpath = basepath + '/' +  entry\n",
    "        print('Classification in progress...')\n",
    "        d = classification_move(imgpath)\n",
    "        df = df.append(list(d.items()),ignore_index=True)\n",
    "    df.columns = ['filename','text']\n",
    "    #df[\"text\"]= df[\"text\"].str.upper().str.title() \n",
    "    #df.text = df.text.str.title()\n",
    "    df.to_csv(savepath, index=False)\n",
    "    \n",
    "    files = os.listdir(normalisedpath)\n",
    "    for f in files:\n",
    "        filename = f.split('.')[0]\n",
    "        temp = os.path.join(normalisedpath,filename + \".jpg\")\n",
    "        shutil.move(temp,backupnorm)\n",
    "    \n",
    "    return print('Exported the file contents to csv, path:/csv/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification in progress...\n",
      "Normalising the image...\n",
      "OCR in progress...\n",
      "D:\\Analytics\\Quarter 4\\Applications of AI\\Final project\\normalised\\iCard_021979_1_Daker_Sarah.jpg\n",
      "iCard_021979_1_Daker_Sarah.jpg\n",
      "Classification in progress...\n",
      "Normalising the image...\n",
      "OCR in progress...\n",
      "D:\\Analytics\\Quarter 4\\Applications of AI\\Final project\\normalised\\iCard_021982_1_Dakin_Hannah_Lois.jpg\n",
      "iCard_021982_1_Dakin_Hannah_Lois.jpg\n",
      "Classification in progress...\n",
      "Normalising the image...\n",
      "OCR in progress...\n",
      "D:\\Analytics\\Quarter 4\\Applications of AI\\Final project\\normalised\\iCard_021988_1_Dako_Martha.jpg\n",
      "iCard_021988_1_Dako_Martha.jpg\n",
      "Exported the file contents to csv, path:/csv/\n"
     ]
    }
   ],
   "source": [
    "ocr_process(basepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
